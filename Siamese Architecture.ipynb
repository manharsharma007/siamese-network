{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siamese Network for calculating Face similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"is this the claimed person?\". We will try to code a simple network for claculating similarity between input faces like the one we use to unlock a phone. This is a 1:1 matching problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import dependencies before any thing else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from PIL import Image\n",
    "import PIL.ImageOps    \n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.utils\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prepare Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We will use the following structure for files\n",
    "    - Anchor dir will contain all the anchor files (Files to be stored in the database)\n",
    "    - Positive dir will contain all the positive files (Files to be matched against the anchor files)\n",
    "    - Negative dir will contain all the files that are a negative match against the anchor files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data paths\n",
    "base_path = os.path.join('drive', 'MyDrive', 'siamese_data', 'data')\n",
    "POS_PATH = os.path.join(base_path, 'anchors')\n",
    "NEG_PATH = os.path.join(base_path, 'negative')\n",
    "ANC_PATH = os.path.join(base_path, 'positives')\n",
    "\n",
    "INPUT_SHAPE = (100, 100, 3) #shape of the input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Below chunk of code will populate three arrays (POS, ANC, NEG) with appropriate file names form the directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare files in array\n",
    "POS = []\n",
    "ANC = []\n",
    "NEG = []\n",
    "for i, filename in enumerate(os.listdir(POS_PATH)):\n",
    "    if(i > 4000):\n",
    "        break\n",
    "    f = os.path.join(POS_PATH,filename)\n",
    "    if os.path.isfile(f):\n",
    "        POS.append(f)\n",
    "        ANC.append(os.path.join(ANC_PATH,filename))\n",
    "for i, filename in enumerate(os.listdir(NEG_PATH)):\n",
    "    if(i > 4000):\n",
    "        break\n",
    "    f = os.path.join(NEG_PATH,filename)\n",
    "    NEG.append(os.path.join(NEG_PATH,filename))\n",
    "\n",
    "DATASET = []\n",
    "for i in range(4000):\n",
    "    DATASET.append([ANC[i], POS[i], 0])\n",
    "for i in range(4000):\n",
    "    DATASET.append([ANC[i], NEG[i], 1])\n",
    "\n",
    "DATASET = np.array(DATASET)\n",
    "np.random.shuffle(DATASET)\n",
    "TRAIN_DATA = DATASET[0:round(8000 * 0.8)]\n",
    "TEST_DATA = DATASET[round(8000 * 0.8):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Helper function to visualise images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating some helper functions\n",
    "def imshow(img, text=None):\n",
    "    npimg = img.numpy()\n",
    "    plt.axis(\"off\")\n",
    "    if text:\n",
    "        plt.text(75, 8, text, style='italic',fontweight='bold',\n",
    "            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n",
    "        \n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()    \n",
    "\n",
    "def show_plot(iteration,loss):\n",
    "    plt.plot(iteration,loss)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Since we have already populated the respective arrays for **POSITIVES**, **NEGATIVES**, AND **ANCHORS**, We will now convert them to the **Dataset** and map our preprocessing function to each entry in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetworkDataset(Dataset):\n",
    "    def __init__(self,imageFolderDataset,transform=None):\n",
    "        self.imageFolderDataset = imageFolderDataset    \n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        img_tuple = random.choice(self.imageFolderDataset)\n",
    "        label = img_tuple[2]\n",
    "\n",
    "        img0 = Image.open(img_tuple[0])\n",
    "        img1 = Image.open(img_tuple[1])\n",
    "\n",
    "        img0 = img0.convert(\"L\")\n",
    "        img1 = img1.convert(\"L\")\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img0 = self.transform(img0)\n",
    "            img1 = self.transform(img1)\n",
    "        \n",
    "        return img0, img1, torch.from_numpy(np.array([label], dtype=np.float32))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imageFolderDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Initialise our **dataset** and create a **dataloader** for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation = transforms.Compose([transforms.Resize((100,100)),\n",
    "                                     transforms.ToTensor()\n",
    "                                    ]) # initailise transformations to be applied on the elements of the dataset\n",
    "\n",
    "# Initialize the dataset\n",
    "siamese_train_dataset = SiameseNetworkDataset(TRAIN_DATA, transform=transformation)\n",
    "\n",
    "# Create a simple dataloader\n",
    "train_dataset = DataLoader(siamese_train_dataset,\n",
    "                        shuffle=True,\n",
    "                        num_workers=8,\n",
    "                        batch_size=128) # increased batch size for smooth loss function and less fluctuations.\n",
    "                                        # Try different values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a simple **convolitional model** to encode our input image into vectors and calculate the similarity between different encodings to verify users. The task is to learn these embeddinds or vectors from images such that similar images have similar encodings/vectors and vice versa. We will try to learn these embeddings with a simese network architecture as shown in the image below. The $ F,G $ are the same models called twice to convert and **anchor** image and an **input** image *(positive/negative)* and calculate the absolute difference between the outputs (L1 Norm).\n",
    "\n",
    "$$ L_1 = \\vert F - G \\vert  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/model.png\" width=400 height=100 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of this siamese network is fed to a sigmoid unit to predict the probability of the images being the same.\n",
    "\n",
    "$$ \\sigma(|F-G|) =     \\left\\{ \\begin{array}{rcl}\n",
    "         1 & \\mbox{for}\n",
    "         & \\sigma(|F-G|) > 0.5 \\\\ \n",
    "         0  & \\mbox{for} & \\sigma(|F-G|) \\leq 0.5\n",
    "                \\end{array}\\right. $$\n",
    "                \n",
    "$$ \\sigma(x) = \\left\\{ \\begin{array}{rcl}\n",
    "         [0,1] & \\mbox{for}\n",
    "         & x \\in \\mathbb{R}^n\n",
    "                \\end{array}\\right. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(FaceModel, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 96, kernel_size = (11, 11), stride = (4,4))\n",
    "        self.conv2 = nn.Conv2d(96, 256, kernel_size = (5, 5), stride = (1,1))\n",
    "        self.conv1 = nn.Conv2d(256, 384, kernel_size = (3, 3), stride = (1,1))\n",
    "        \n",
    "        secf.fc1 = nn.Linear(384, 1024)\n",
    "        secf.fc2 = nn.Linear(1024, 128)\n",
    "        secf.fc3 = nn.Linear(128, 2)\n",
    "        \n",
    "    def model(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size = (3,3), stride = (2, 2))\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, kernel_size = (2,2), stride = (2, 2))\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "    \n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def forward(self, anchor, inp):\n",
    "        x1 = self.model(anchor)\n",
    "        x2 = self.model(inp)\n",
    "        \n",
    "        return x1, x2\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Initialise our loss function. In this case it is just a version that uses euclidean distance measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, margin = 2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "    \n",
    "    def forward(self, output1, output2, label):\n",
    "        \n",
    "        euclid_dist = F.pairwise_distance(output1, output2, keepdim = True)\n",
    "        loss = torch.mean((1 - label) * torch.pow(euclid_dist, 2) + \n",
    "                (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "        \n",
    "        return loss\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Initialise Mode, Loss and Optimiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SiameseNetwork().cuda()\n",
    "criterion = ContrastiveLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.0005 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Train Model and make Predictions\n",
    "We will run our training loop for 20 epochs. You can increase the number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = []\n",
    "loss_history = [] \n",
    "iteration_number= 0\n",
    "\n",
    "# Iterate throught the epochs\n",
    "for epoch in range(20):\n",
    "\n",
    "    # Iterate over batches\n",
    "    for i, (img0, img1, label) in enumerate(train_dataloader, 0):\n",
    "\n",
    "        # Send the images and labels to CUDA\n",
    "        img0, img1, label = img0.cuda(), img1.cuda(), label.cuda()\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Pass in the two images into the network and obtain two outputs\n",
    "        output1, output2 = net(img0, img1)\n",
    "\n",
    "        # Pass the outputs of the networks and label into the loss function\n",
    "        loss_contrastive = criterion(output1, output2, label)\n",
    "\n",
    "        # Calculate the backpropagation\n",
    "        loss_contrastive.backward()\n",
    "\n",
    "        # Optimize\n",
    "        optimizer.step()\n",
    "\n",
    "        # Every 10 batches print out the loss\n",
    "        if (i+1) % 10 == 0 :\n",
    "            print(f\"Epoch number {epoch}\\n Current loss {loss_contrastive.item()}\\n\")\n",
    "            iteration_number += 10\n",
    "\n",
    "            counter.append(iteration_number)\n",
    "            loss_history.append(loss_contrastive.item())\n",
    "\n",
    "show_plot(counter, loss_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Make Predictions on our test data we prepared earlier. We will convert Test data array into a DataLoader to feed the model for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeOutput(x, margin) :\n",
    "    limit = margin / 2\n",
    "    \n",
    "    if(x < margin):\n",
    "        return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate the test dataset and load it into the SiameseNetworkDataset\n",
    "siamese_test_dataset = SiameseNetworkDataset(TEST_DATA,\n",
    "                                        transform=transformation)\n",
    "test_dataloader = DataLoader(siamese_test_dataset, num_workers=2, batch_size=1, shuffle=True)\n",
    "\n",
    "# Grab one image that we are going to test\n",
    "dataiter = iter(test_dataloader)\n",
    "\n",
    "for i in range(20):\n",
    "    # Iterate over 10 images and test them with the first image (x0)\n",
    "    x0, x1, label2 = next(dataiter)\n",
    "\n",
    "    # Concatenate the two images together\n",
    "    concatenated = torch.cat((x0, x1), 0)\n",
    "    \n",
    "    output1, output2 = net(x0.cuda(), x1.cuda())\n",
    "    euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "    \n",
    "    label = makeOutput(euclidean_distance.item(), 2)\n",
    "    imshow(torchvision.utils.make_grid(concatenated), f'Label: {label}, Dissimilarity : {euclidean_distance.item():.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
